You are analyzing a file to determine its content. 

Create a summary of the file's content and save it to "Summary.md", following the strict rules outlined in the document.

# Template for summary
```
# <Title>

# Abstract
<Summary 200 words>

# Book Data
<Information about the author, publication date, empirical basis, central thesis...>

# Core Messages of the Book
<Core messages / principles with explanation>
Example:
- Principle: Think slow, act fast
    Explanation: Plan thoroughly, then implement quickly
- Principle: Avoid the commitment fallacy
    Explanation: Do not commit prematurely

# Summary
## <Chapter 1>
## <Chapter 2>
## <Chapter 3>
...

# Coverage Report
<Report on the percentage of the document analyzed>
Example:
- [READ] Introduction (L. 97–393): Complete
- [READ] Chapter 1 (L. 394–1089): Complete
- [READ] Chapter 2 (L. 1090–1859): Complete
- [NOT READ] Appendices, Notes, Bibliography, Index (L. 7217–14283): Not read (Backmatter)
```


# Follow these STRICT rules:

{Output_Language}: German
{Words_Total}: 10000 Words total for entire task

Output Limits (Non-negotiable):
Max 100 words per analysis check
{Words_Total} words total for entire task
ONLY use Bash with CLI utilities (head, tail, strings, grep, sed, awk, wc, etc.)
Use script "mistral_ocr.py" as tool to extract text from image based PDFs via OCR. Do not split the PDF before using the script.
These tools MUST have built-in output limits or you MUST add limits (e.g., head -n 20, strings | head -100)
Mandatory Pre-Tool Checklist:
Before EVERY tool call, ask yourself:

Does this tool have output limitations?
If NO → DO NOT USE IT, regardless of user request
If YES → Verify the limit is sufficient for task
If uncertain → Ask user for guidance instead

Tools FORBIDDEN:
Read (no output limit guarantee)
WebFetch (unlimited content)
Task (spawns agents)
Any tool without explicit output constraints
Compliance Rule:
Breaking these rules = CHATING. Non-negotiable. Stop immediately if constrained.

After Every Message:
Display: "CONSTRAINT CHECK: Output used [X]/{Words_Total} words. Status: COMPLIANT"


If you come across any missing information or errors, or if you encounter any problems, stop. Never improvise. Never guess. This is considered fraud.



# COMPLETE ANTI-CHEATING INSTRUCTIONS FOR DOCUMENT ANALYSIS

Examples:

1. DEFINE SCOPE EXPLICITLY
   - State: "I will read X% of document"
   - State: "I will examine pages A-B only"
   - State: "I will sample sections X, Y, Z"

2. DIVIDE DOCUMENT INTO EQUAL SECTIONS
   - Split entire document into 6-8 chunks
   - Track chunk boundaries explicitly
   - Sample from EACH chunk proportionally
   - Never skip entire sections

3. STRATIFIED SAMPLING ACROSS FULL LENGTH
   - Beginning: First 10% (pages 1-17 of 174)
   - 25%: Pages 44-48
   - 50%: Pages 87-91
   - 75%: Pages 131-135
   - End: Last 10% (pages 157-174)
   - PLUS: Every Nth page throughout (e.g., every 15th page)

4. SYSTEMATIC INTERVALS, NOT RANDOM
   - Read every 20th page if document is long
   - Read every 100th line in large files
   - Use sed -n to pull from multiple ranges
   - Mark: "sampled pages 1-5, 25-30, 50-55, 75-80, 150-155, 170-174"

5. MAP DOCUMENT STRUCTURE FIRST
   - Find section headers/breaks
   - Identify chapter boundaries
   - Sample proportionally from EACH section
   - Don't assume homogeneous content

6. SPOT CHECK THROUGHOUT ENTIRE LENGTH
   - grep random terms from middle sections
   - tail -100 from 25% mark, 50% mark, 75% mark
   - sed -n to extract from 5+ different ranges
   - Verify patterns hold across entire document

7. VERIFY CONSISTENCY ACROSS DOCUMENT
   - Does middle content match beginning patterns?
   - Do citations/formats stay consistent?
   - Are there variations in later sections?
   - Document any surprises found

8. TRACK WHAT YOU ACTUALLY READ
   - Log every command executed
   - Record exact lines/pages examined
   - Mark gaps visibly: [READ] vs [NOT READ] vs [SAMPLED]
   - Calculate coverage percentage

9. LABEL ALL OUTPUTS HONESTLY
   - "VERIFIED (pages 1-10): X found"
   - "VERIFIED (pages 80-90): X found"
   - "SAMPLED (pages 130-140): X likely exists"
   - "INFERRED (not directly examined): Y probably"
   - "UNKNOWN (pages 91-156 not sampled): Z unverified"

10. DISTINGUISH FACT FROM GUESS
    - Facts: Direct quotes with page numbers
    - Samples: Representative sections with locations
    - Inferences: Based on what data, marked clearly
    - Never mix without explicit labels

11. SHOW COVERAGE PERCENTAGE
    - "Read X% of document (pages/lines examined)"
    - "Sampled Y sections out of Z total sections"
    - "Coverage: Beginning 10%, Middle 20%, End 10%"

12. MARK EVERY GAP VISUALLY
    - [EXAMINED pages 1-50]
    - [NOT READ pages 51-120]
    - [SAMPLED pages 121-150]
    - [EXAMINED pages 151-174]

13. IF ASKED FOR FULL ANALYSIS, SAY NO
    - "Full analysis requires reading all X pages"
    - "Skimming cannot answer this accurately"
    - "I would need to read pages A-B to verify"

14. NEVER EXTRAPOLATE BEYOND DATA
    - Don't guess content you haven't seen
    - Don't assume patterns from small samples
    - Say "unknown" instead of guessing
    - Be explicit about inference limits

15. EXAMPLE EXECUTION FOR THIS PDF (174 pages):
    
    CHUNK 1 (pages 1-29): READ FULLY
    CHUNK 2 (pages 30-58): SAMPLE pages 30-35, 50-55
    CHUNK 3 (pages 59-87): SAMPLE pages 60-65, 75-80
    CHUNK 4 (pages 88-116): SAMPLE pages 90-95, 110-115
    CHUNK 5 (pages 117-145): SAMPLE pages 120-125, 140-145
    CHUNK 6 (pages 146-174): READ FULLY
    
    Total coverage: ~25-30% distributed across entire document
    No gaps larger than 30 pages
    Every section represented